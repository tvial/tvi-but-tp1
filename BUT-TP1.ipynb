{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2409e0a-9091-4599-b265-e489412e8481",
   "metadata": {},
   "source": [
    "# Pr√©sentation de Jupyter Notebook\n",
    "\n",
    "Vous √™tes en train de consulter et d'ex√©cuter un **notebook Jupyter**. C'est un √©diteur hybride, permettant d'√©crire de la documentation et d'ex√©cuter du code (ici du code Python). Les notebooks Jupyter ou d√©riv√©s sont tr√®s utilis√©s en data engineering et en data science.\n",
    "\n",
    "L'√©diteur fonctionne √† base de cellules, et elles sont de 2 types :\n",
    "- des cellules de texte, dites \"Markdown\". En double-cliquant dessus, on √©dite directement le code Markdown. Ce formalisme permet de d√©corer le texte avec du formatage l√©ger : gras, italique, listes √† puces, ch√¢sse fixe pour y mettre des extraits de code, formules math√©matiques, ...\n",
    "- des cellules de code, pour ex√©cuter des instructions Python. Les variables et fonctions d√©clar√©es dans les cellules de code sont disponibles dans l'ensemble du notebook, on peut y faire r√©f√©rence d'une cellule √† l'autre. Un simple clic permet de les modifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a4bd8-7d45-4eed-826f-56dc9003be1d",
   "metadata": {},
   "source": [
    "## Edition du contenu\n",
    "Apr√®s avoir modifi√© une cellule, on la valide en faisant **\\[Shift+Enter\\]**. Une cellule de texte sera affich√©e en appliquant le formatage Markdown, et une cellule de code ex√©cutera effectivement le code Python qui est dedans. Le focus passera √† la cellule suivante.\n",
    "\n",
    "Parfois on a besoin d'ajouter ou supprimer une cellule en plein milieu du document. Voici les commandes pour le faire :\n",
    "- ajouter une cellule **au-dessus** de la cellule active : appuyer d'abord sur **\\[Esc\\]** pour sortir du mode d'√©dition, puis la touche **\\[A\\]** (pour _above_). Menu correspondant de la barre d'outils contextuelle : _Insert Cell Above_\n",
    "- ajouter une cellule **au-dessous** de la cellule active : appuyer d'abord sur **\\[Esc\\]**, puis la touche **\\[B\\]** (pour _below_). Menu correspondant : _Insert Cell Below_, ou le bouton \\[‚úö\\] de la barre d'outils principale\n",
    "- supprimer la cellule active : appuyer d'abord sur **\\[Esc\\]**, puis 2 fois la touche **\\[D\\]**. Menu correspondant : _Edit_ > _Delete Cells_\n",
    "- pour changer le type de la cellule active (texte / code) : d'abord **\\[Esc\\]**, puis ensuite **\\[M\\]** pour du texte, ou **\\[Y\\]** pour du code. On peut aussi utiliser la petite liste de la barre d'outils, entre _Markdown_ (texte) et _Code_. Les autres types de cellule sont inutiles ici.\n",
    "- annuler une fausse manip sur les cellules (une suppression par exemple) : **\\[Esc\\]** puis **\\[Z\\]**\n",
    "- des fonctions de copier/couper-coller de cellules enti√®res sont aussi possibles, via les touches **\\[X\\]** (couper), **\\[C\\]** (copier) et **\\[V\\]** (coller), ou via le menu _Edit_. Pensez √† faire **\\[Esc\\]** √† chaque fois avant si vous √™tes en mode √©dition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65512f-3aaf-4202-8fe2-e2bb209689f1",
   "metadata": {},
   "source": [
    "## Quelques conseils\n",
    "- pensez √† sauver r√©guli√®rement le notebook (bouton \\[üñ´\\]) : cela ne garde pas les variables et fonctions Python qui sont en m√©moire, mais tout le contenu texte & code du notebook, que l'on peut r√©ex√©cuter pour \"recr√©er\" les variables & fonctions √† un autre moment\n",
    "- veillez √† garder un ordre logique entre les cellules de code : si une variable ou une fonction est d√©finie quelque part, il faut l'utiliser dans la m√™me cellule, ou une des suivantes. Evitez d'√©crire du code qui d√©pende de l'ex√©cution pr√©alable d'une cellule qui se trouve plus loin, car je ne saurai pas dans quel ordre ex√©cuter les cellules !\n",
    "- de temps en temps, et en particulier quand on pense que tout est au point, il est utile de tout r√©ex√©cuter d'un coup, au moyen de la commande ad√©quate (bouton avec le symbole \\[üûÇüûÇ\\]). Cela va vider la m√©moire Python et tout relancer dans l'ordre d'√©criture du notebook. Si vous avez des probl√®mes d'ordre d'ex√©cution des cellules, cela se verra √† ce moment-l√† !\n",
    "- n'h√©sitez pas √† commenter vos choix et votre code, soit dans les cellules Python avec la syntaxe `# Un commentaire blablabla`, soit avec des cellules de texte bien plac√©es. Le r√©sultat d'un travail sur notebbok doit √™tre une sorte de mini-rapport m√©langeant r√©flexions autour du probl√®me et code d'impl√©mentation de la solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bcd96-97df-4550-a395-3e4d98f6aab2",
   "metadata": {},
   "source": [
    "**L'interface et ses raccourcis claviers peuvent √™tre un peu d√©routants au d√©but, si vous avez peur d'avoir fait une fausse manip et ne savez pas comment la r√©parer, demandez-moi et on r√®glera √ßa ensemble**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65263f9-21de-43f1-bb39-016920261717",
   "metadata": {},
   "source": [
    "# Description du cas\n",
    "\n",
    "Cet exercice a pour but la manipulation de donn√©es structur√©es au format Parquet.\n",
    "\n",
    "Nous allons traiter les donn√©es d'une entreprise industrielle fictive, Blabla Inc. Les donn√©es concernent 2 **sites** (usines) de l'entreprise : Naves et Villemomble.\n",
    "\n",
    "Chaque site comporte plusieurs **ateliers** (_workshops_), et chaque atelier poss√®de une ou plusieurs **machines**.\n",
    "\n",
    "Enfin, chaque machine enregistre son √©tat √† une fr√©quence donn√©e, √©tat constitu√© d'une ou plusieurs mesures, selon son type. Ainsi, √† chaque machine est associ√©e un certain nombre de **s√©ries temporelles**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da15b2-f6b1-47cf-9283-26746900d96f",
   "metadata": {},
   "source": [
    "## Ce qui est demand√©\n",
    "\n",
    "Il est demand√© de lire les donn√©es d'entr√©e (JSON et CSV), de les traiter en m√©moire (elles sont peu volumineuses), et de les mettre en forme avant de les stocker au **format Parquet** selon un mod√®le attendu.\n",
    "\n",
    "Le notebook va vous guider dans cette t√¢che. Voyons d'abord les donn√©es √† manipuler.\n",
    "\n",
    "Lorsque vous voyez un marqueur du type `### CHANGE ME ###` dans le code, ou dans un commentaire, c'est qu'il y a quelque chose √† compl√©ter pour accomplir une t√¢che."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6e406-d7dd-4805-9b3f-0b35e518be6d",
   "metadata": {},
   "source": [
    "## Les donn√©es\n",
    "\n",
    "Les donn√©es se trouvent dans le r√©pertoire `data/` de votre notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca5beb-2de9-4e81-9c95-012fe917b322",
   "metadata": {},
   "source": [
    "### L'organisation des sites et ateliers\n",
    "\n",
    "L'organisation de Blabla Inc. est d√©crite de mani√®re hi√©rarchique dans le fichier `equipments.json`, qui contient un objet `organization` avec la structure suivante :\n",
    "- `name` : nom de l'entreprise\n",
    "- `sites` : liste des sites de l'entreprise, avec pour chacun :\n",
    "  - `name` : nom du site\n",
    "  - `workshops` : liste des ateliers, avec pour chacun :\n",
    "    - `name` : nom de l'atelier\n",
    "    - `machines` : liste des ID de machines pr√©sentes dans l'atelier (de 1 √† 3 machines selon le site et l'atelier)\n",
    "\n",
    "<u>Extrait du fichier :</u>\n",
    "```\n",
    "{\n",
    "\t\"organization\": {\n",
    "\t\t\"name\": \"Blabla Inc.\",\n",
    "\t\t\"sites\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"name\": \"Naves\",\n",
    "\t\t\t\t\"workshops\": [\n",
    "\t\t\t\t\t{\"name\": \"Pr√©paration\", \"machines\": [\"NP1\"]},\n",
    "\t\t\t\t\t{\"name\": \"Usinage\", \"machines\": [\"NU1\", \"NU2\", \"NU3\"]},\n",
    "                    ...\n",
    "\t\t\t\t]\n",
    "\t\t\t},\n",
    "            ...\n",
    "\t\t]\n",
    "\t}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0dd1b-8a10-431a-a7b1-17429ed9a43f",
   "metadata": {},
   "source": [
    "### Les \"mappings\" de noms de machines\n",
    "\n",
    "Les ID de machines qui sont dans le fichier d'organisation, sont des noms codifi√©s qu'un utilisateur final aurait du mal √† interpr√©ter. Dans l'exercice, il est demand√© de mettre √† la place les noms \"lisibles\" des machines ; pour cela il faut une correspondance.\n",
    "\n",
    "La table de correspondance est dans le fichier `mapping.csv`, qui liste toutes les machines avec pour chacune :\n",
    "- `machine_id` : ID de la machine (m√™me nomenclature que dans `equipments.json`)\n",
    "- `machine_name` : nom lisible de la machine (celui √† reprendre dans les fichier de sortie)\n",
    "\n",
    "<u>Extrait du fichier :</u>\n",
    "```\n",
    "machine_id;machine_name\n",
    "NP1;Golgoth 3000\n",
    "NU1;Fraisator-1\n",
    "NU2;Fraisator-2\n",
    "NU3;Fraisator-3\n",
    "NA1;Lego_A\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5fd98-9ad7-4819-93e0-5933eb923a89",
   "metadata": {},
   "source": [
    "### Les s√©ries temporelles\n",
    "\n",
    "Les s√©ries sont des groupes de fichiers, dans le r√©pertoire `data/ts/`, √† raison de plusieurs fichiers par machine. Concr√®tement, les fichiers sont nomm√©s `ID_n.csv`, o√π `ID` est l'ID de machine, et `n` le num√©ro de s√©quence du fichier, de 1 √† 26. En effet, les s√©ries couvrent une p√©riode d'environ 1 semaine, et sont d√©coup√©es par blocs de 8h.\n",
    "\n",
    "La structure de chaque fichier CSV est la suivante :\n",
    "- `timestamp` : la date et l'heure du point de mesure (format aaaa-mm-jj hh:mm:ss)\n",
    "- un champ par type de mesure, en fonction de l'atelier o√π se trouve la machine :\n",
    "  - \"Pr√©paration\" : `scanned_products` est un entier donnant le nombre de produits point√©s √† l'√©tape de pr√©paration\n",
    "  - \"Usinage\" : `rotation_x`, `rotation_y` et `rotation_z` sont 3 flottants indiquant l'orientation de la t√™te d'usinage, en degr√©s\n",
    "  - \"Assemblage\" : `products` est un entier donnant le nombre de produits assembl√©s\n",
    "  - \"Four\" : `temperature` est la temp√©rature du four (en ¬∞C), `humidity` son degr√© d'hygrom√©trie (en %)\n",
    "  - \"M√©trologie\" : `products` est un entier donnant le nombre de produits finis contr√¥l√©s, et `width`, `length` et `height` (en cm) le r√©sultat de la derni√®re mesure\n",
    "\n",
    "Noter que les timestamps sont irr√©guliers : pour un atelier donn√©, la fr√©quence de mesure est √† peu pr√®s constante mais il y a toujours un peu de d√©calage (ex. pour une mesure toutes les 30 secondes, cela peut √™tre 08:10:01, 08:10:33, 08:10:59, ...). Les fr√©quences ne sont pas les m√™mes d'un atelier √† l'autre.\n",
    "\n",
    "Tous les fichiers ont les noms de champs en en-t√™te.\n",
    "\n",
    "<u>Exemple pour un four :</u>\n",
    "```\n",
    "timestamp,temperature,humidity\n",
    "2024-01-28 00:00:07,812,93\n",
    "2024-01-28 00:00:17,812,93\n",
    "2024-01-28 00:00:27,812,93\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17de57-f166-459e-8c25-62dca7e1a8c8",
   "metadata": {},
   "source": [
    "# Imports de packages Python\n",
    "Nous aurons besoin de ces packages pour manipuler les fichiers.\n",
    "\n",
    "- `pandas` : manipulation de dataframes en m√©moire\n",
    "- `json` : pour la lecture des donn√©es JSON\n",
    "- `glob` : √©num√©ration des fichiers de donn√©es dans un r√©pertoire\n",
    "- `os` : nous utiliserons ici les fonctions de manipulation de chemins de fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f938b-f4ea-4157-a915-92031ac1ae33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4459e-89f2-4669-b367-e1617b8a327b",
   "metadata": {},
   "source": [
    "# Lecture des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc208b-26cd-44ea-b9d5-65241c2ac732",
   "metadata": {},
   "source": [
    "## Organisation\n",
    "C'est un fichier JSON que nous pouvons lire directement, ce qui donne un dictionnaire Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4c24e-3596-4993-9848-a47b18a324e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/equipments.json', 'r') as f:\n",
    "    equipments = json.load(f)\n",
    "    \n",
    "equipments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb20f41-7780-4d5a-b911-324a2a0f99f4",
   "metadata": {},
   "source": [
    "## Mapping des noms de machines\n",
    "C'est un fichier CSV, mais nous avons besoin de le transformer en dictionnaire donnant, pour chaque ID de machine, son nom. Nous l'enrichissons ensuite avec d'autres infos de l'√©quipement, qui indiquent o√π se trouve la machine (site, atelier).\n",
    "\n",
    "Nous utilisons la fonction `read_csv()` de Pandas, qui permet de lire un fichier √† partir de son nom / chemin, en pr√©cisant le caract√®re (`sep`) qui s√©pare les champs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cfef0f-7d71-4ba0-9217-cea34394ef2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Lecture du fichier sous forme de dataframe\n",
    "#\n",
    "# Attendu : un dataframe de la forme (ordre des lignes indiff√©rent, et ne pas tenir compte de l'index de ligne (nombres en gras) qui s'afficheront en sortie) :\n",
    "#\n",
    "# +------------+--------------+\n",
    "# | machine_id | machine_name |\n",
    "# +------------+--------------+\n",
    "# |        NP1 | Golgoth 3000 |\n",
    "# |        NU1 |  Fraisator-1 |\n",
    "# |        NU2 |  Fraisator-2 |\n",
    "# |        ... |          ... |\n",
    "# |        VM1 |     Sherlock |\n",
    "# +------------+--------------+\n",
    "\n",
    "mapping = pd.read_csv('### CHANGE ME ###', sep='### CHANGE ME ###')\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecf6f2-3058-4334-890a-7e2502251bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Transformation en dictionnaire Python, en it√©rant sur les lignes du dataframe\n",
    "# On fait un dictionnaire de petits dictionnaires {'machine_name': xxx}, pour pouvoir l'enrichir dans l'√©tape d'apr√®s\n",
    "#\n",
    "# Attendu : un dictionnaire de la forme :\n",
    "#\n",
    "# {'NP1': {'machine_name': 'Golgoth 3000'},\n",
    "#  'NU1': {'machine_name': 'Fraisator-1'},\n",
    "#  'NU2': {'machine_name': 'Fraisator-2'},\n",
    "#  'NU3': {'machine_name': 'Fraisator-3'},\n",
    "#  'NA1': {'machine_name': 'Lego_A'},\n",
    "#  ...\n",
    "#  'VP2': {'machine_name': 'Cleanomatic-2'}]\n",
    "\n",
    "mapping = {\n",
    "    row['machine_id']: { ### CHANGE ME ### }\n",
    "    for _, row in mapping.iterrows()\n",
    "}\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a27b2c-f5f2-4c90-a1b1-bdd6fd806d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Enrichissement avec les donn√©es d'√©quipement\n",
    "# A l'issue de cette √©tape, chaque ID de machine est associ√© √† toutes les infos de la machine\n",
    "#\n",
    "# Attendu : un dictionnaire de la forme :\n",
    "#\n",
    "# {'NP1': {'machine_name': 'Golgoth 3000', 'site': 'Naves', 'workshop': 'Pr√©paration'},\n",
    "#  'NU1': {'machine_name': 'Fraisator-1', 'site': 'Naves', 'workshop': 'Usinage'},\n",
    "#  'NU2': {'machine_name': 'Fraisator-2', 'site': 'Naves', 'workshop': 'Usinage'},\n",
    "#  'NU3': {'machine_name': 'Fraisator-3', 'site': 'Naves', 'workshop': 'Usinage'},\n",
    "#  'NA1': {'machine_name': 'Lego_A', 'site': 'Naves', 'workshop': 'Assemblage'},\n",
    "#  ...\n",
    "#  'VM1': {'machine_name': 'Sherlock', 'site': 'Villemomble', 'workshop': 'M√©trologie'}}\n",
    " \n",
    "for site in equipments['### CHANGE ME ###']['### CHANGE ME ###']:\n",
    "    for workshop in site['### CHANGE ME ###']:\n",
    "        for machine_id in workshop['### CHANGE ME ###']:\n",
    "            mapping_machine = mapping[machine_id]\n",
    "            ### CHANGE ME ### (ajouter le nom du site, le nom du workshop)\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6b2c3-c939-4478-9591-4a03f2d8b4e7",
   "metadata": {},
   "source": [
    "## S√©ries temporelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd821b54-2dd7-4532-a35e-962d7c0e28e4",
   "metadata": {},
   "source": [
    "Les s√©ries sont dans plusieurs fichiers CSV, qu'on va regrouper sous forme d'un unique dataframe par machine (rep√©r√©e par son ID, pr√©sent dans le nom de chaque fichier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e879ec-2e05-47bb-8522-556a0216d829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Enum√©ration des fichiers de s√©ries, dans le r√©pertoire correspondant\n",
    "ts_filenames = glob.glob('data/ts/*.csv')\n",
    "print(f'{len(ts_filenames)} fichiers de s√©ries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba033c15-4972-481b-b73b-cd1eb266d39c",
   "metadata": {},
   "source": [
    "Ceci vous sera utile pour √©crire le bout de code manquant :\n",
    "- un param√®tre suppl√©mentaire √† la fonction `read_csv()` : `parse_dates`\n",
    "  - la plupart du temps, la fonction va d√©tecter le type des donn√©es pr√©sentes dans le fichier, et les m√©moriser dans les m√©tadonn√©es du dataframe. Cependant, cela est valable pour les nombres et cha√Ænes de caract√®re. Pour les dates et heures (ou timestamps) il faut l'aider un petit peu en lui donnant le nom des champs qui en contiennent\n",
    "  - concr√®tement, il vous faudra ajouter un param√®tre `parse_dates=['nom de champ']` pour lui dire quoi interpr√©ter\n",
    "- la fonction `concat()` de Pandas (`pd.concat()`) qui permet de mettre bout √† bout 2 dataframes pour en cr√©er un unique. On lui passe en param√®tre une liste de dataframes √† concat√©ner, ex. `[df1, df2, df3, ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce830f78-5ffa-471c-a9ca-6d6ef79f9a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Agr√©gation des s√©ries. Pour chaque fichier CSV de s√©rie temporelle :\n",
    "# - extraction de l'ID de machine, √† partir du nom du fichier\n",
    "# - lecture du fichier CSV dans un petit dataframe\n",
    "# - concat√©nation avec le dataframe pr√©c√©dent de la machine\n",
    "# Le tout est stock√© dans un dictionnaire de dataframes, |dataframes_per_machine`\n",
    "#\n",
    "# Type de sortie attendue √† la fin (ordre indiff√©rent) :\n",
    "#\n",
    "# Machine NP1: 25397 √©chantillons\n",
    "# Machine NU1: 166442 √©chantillons\n",
    "# Machine NU2: 166357 √©chantillons\n",
    "# Machine NU3: 166364 √©chantillons\n",
    "# ...\n",
    "# Machine VM1: 9423 √©chantillons\n",
    "#\n",
    "# +---------------------+-------------+------------+------------+\n",
    "# |           timestamp | rotationx_x | rotation_y | rotation_z |\n",
    "# +---------------------+-------------+------------+------------+\n",
    "# | 2024-01-29 16:00:03 |   88.763247 | -49.428614 | 133.959195 |\n",
    "# | 2024-01-29 16:00:08 |   90.583300 | -49.193791 | 134.367569 |\n",
    "# | 2024-01-29 16:00:13 |   88.727491 | -52.121831 | 136.238264 |\n",
    "# |                 ... |         ... |        ... |        ... |\n",
    "# | 2024-01-26 15:59:56 | -174.516082 | 52.336152  |  79.645205 |\n",
    "# +---------------------+-------------+------------+------------+\n",
    "\n",
    "\n",
    "# Initialise le dictionnaire avec des dataframes vides\n",
    "dataframes_per_machine = {\n",
    "    machine_id: pd.DataFrame()\n",
    "    for machine_id in mapping\n",
    "}\n",
    "\n",
    "\n",
    "# Parcourt les fichiers\n",
    "for filename in ts_filenames:\n",
    "    # Extraction de l'ID de machine\n",
    "    machine_id = os.path.basename(filename).split('_')[0]\n",
    "          \n",
    "    small_dataframe = ### CHANGE ME ###\n",
    "    dataframes_per_machine[machine_id] = ### CHANGE ME ###\n",
    "\n",
    "for machine_id, machine_dataframe in dataframes_per_machine.items():\n",
    "    print(f'Machine {machine_id}: {len(machine_dataframe)} √©chantillons')\n",
    "    \n",
    "dataframes_per_machine['NU2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ecc88-1472-4dc8-8beb-68d59ad84b4e",
   "metadata": {},
   "source": [
    "Pour ajouter une nouvelle colonne √† un dataframe `df`, on peut utiliser la syntaxe suivante : `df['nouvelle_colonne'] = valeur`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc30022-0557-4ef0-b639-cb1ffa6b369e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Ajout au dataframe des infos de nom de machine, de site et d'atelier\n",
    "#\n",
    "# Attendu un dataframe enrichi :\n",
    "# +---------------------+-------------+------------+------------+--------------+-------+----------+\n",
    "# |           timestamp | rotationx_x | rotation_y | rotation_z | machine_name |  site | workshop |\n",
    "# +---------------------+-------------+------------+------------+--------------+-------+----------+\n",
    "# | 2024-01-29 16:00:03 |   88.763247 | -49.428614 | 133.959195 |  Fraisator-2 | Naves | Usinage  |\n",
    "# | 2024-01-29 16:00:08 |   90.583300 | -49.193791 | 134.367569 |  Fraisator-2 | Naves | Usinage  |\n",
    "# | 2024-01-29 16:00:13 |   88.727491 | -52.121831 | 136.238264 |  Fraisator-2 | Naves | Usinage  |\n",
    "# |                 ... |         ... |        ... |        ... |  Fraisator-2 | Naves | Usinage  |\n",
    "# | 2024-01-26 15:59:56 | -174.516082 | 52.336152  |  79.645205 |  Fraisator-2 | Naves | Usinage  |\n",
    "# +---------------------+-------------+------------+------------+--------------+-------+----------+\n",
    "\n",
    "for machine_id, df in dataframes_per_machine.items():\n",
    "    ### CHANGE ME ###\n",
    "    \n",
    "dataframes_per_machine['NU2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6eb36c-a610-4bf2-a921-9c82e538699f",
   "metadata": {},
   "source": [
    "# Ecriture du r√©sultat brut\n",
    "On sauvegarde chaque dataframe de machine dans le r√©pertoire de sortie, en it√©rant sur le dictionnaire cr√©√© pr√©c√©demment.\n",
    "\n",
    "Pandas a des fonctions `read_xxx()` (ex. `read_csv()`) pour la lecture, et √† l'inverse, des fonctions `to_xxx()` (ex. `to_parquet()`) pour les √©critures de dataframes en m√©moire.\n",
    "\n",
    "Le param√®tre `index=False` emp√™che l'√©criture des index de lignes (nombres en gras) dans le fichier, car dans notre cas ils n'ont pas de signification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74875e5a-f36b-44c9-bee5-82850a2f0af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for machine_id, machine_dataframe in dataframes_per_machine.items():\n",
    "    machine_dataframe.to_parquet(f'data/ts_parquet/{machine_id}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb4335-0cc0-4370-b477-9e72d96583b9",
   "metadata": {},
   "source": [
    "Vous pouvez consulter le r√©pertoire `data/ts_parquet` dans le bandeau de gauche, pour constater que les fichiers ont bien √©t√© cr√©√©s (un par machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df7b0a-610a-4d76-92a3-61451b2b6ee4",
   "metadata": {},
   "source": [
    "# Ecriture du r√©sultat - avec partitionnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a496e-41f4-4c28-bc49-0e955a9a1cb2",
   "metadata": {},
   "source": [
    "Ci-dessous, on extrait le jour du timestamp :\n",
    "- la fonction `.dt.strftime(format)` transforme un champ date de Pandas en cha√Æne de caract√®res, en appliquant un format de repr√©sentation\n",
    "- on ajoute une colonne virtuelle au dataframe `machine_dataframe` via la m√©thode `.assign(day=day)`. Contrairement √† la notation `df['nouvelle_colonne'] = valeur`, le dataframe n'est pas modifi√©, mais les m√©thodes qu'on applique sur le r√©sultat -- et uniquement celles-ci -- tiennent compte de cette colonne virtuelle\n",
    "- noter que `day` n'est pas une valeur constante, mais une s√©rie, c'est-√†-dire une liste de valeurs analogue √† une colonne de dataframe (ce qui fait qu'on peut la lui assigner)\n",
    "\n",
    "Puis on √©crit le fichier partitionn√© comme il faut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8364634-f97d-4ec4-b0fd-99eaf4835f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for machine_id, machine_dataframe in dataframes_per_machine.items():\n",
    "    day = machine_dataframe.timestamp.dt.strftime('%Y-%m-%d')\n",
    "    machine_dataframe.assign(day=day).to_parquet(f'data/ts_parquet_part/{machine_id}', index=False, partition_cols=[### CHANGE ME ###])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f5e92-7a4d-4a3f-a2d9-44b90d7d9c8e",
   "metadata": {},
   "source": [
    "Vous pouvez aller consulter le r√©pertoire `data/ts_parquet_part` pour voir comment Pandas (et son partenaire PyArrow) stockent les fichiers Parquet partitionn√©s.\n",
    "\n",
    "NB : si vous essayez plusieurs fois l'√©criture partitionn√©e, les fichiers vont s'accumuler ; il faudrait normalement les supprimer avant mais nous ne le faisons pas ici, par simplicit√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765a402-1086-4345-a6d9-1791324a9ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
